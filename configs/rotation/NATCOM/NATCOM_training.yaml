data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: dataset.rotation.rotation_dataset
        class: DocOrientationDataset
        DocOrientationDataset:
          data_dirs:
            - '''/extdata/ocr/phungpx/projects/PHUNGPX/semantic_segmentation_pytorch/dataset/NATCOM2/train'''
          classes:
            CARD_FRONT_TYPE_1: 0
            CARD_BACK_TYPE_1: 1
          image_patterns:
            - '''**/*_quad.jpg'''
            - '''**/*_quad.png'''
            - '''**/*_quad.jpeg'''
            - '''**/*_quad.JPG'''
            - '''**/*_quad.PNG'''
            - '''**/*_quad.JPEG'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          image_size: (224, 224)
          inner_size: 256
          max_transforms: 7
          transforms:
            - 'iaa.Add(value=(-50, 50), per_channel=True)'
            - 'iaa.AdditiveGaussianNoise(loc=(-5, 5), scale=10, per_channel=True)'
            - 'iaa.Dropout(p=(0, 0.2))'
            - 'iaa.GammaContrast()'
            - 'iaa.JpegCompression(compression=(0, 50))'
            - 'iaa.GaussianBlur(sigma=(0, 2))'
            - 'iaa.MotionBlur()'
            - 'iaa.AddToHueAndSaturation(value=(-50, 50))'
            - 'iaa.PerspectiveTransform(scale=(0, 0.1))'
            - 'iaa.Pad(percent=(0, 0.1))'
            - 'iaa.Crop(percent=(0, 0.2))'
            - 'iaa.Grayscale(alpha=(0, 1))'
            - 'iaa.ChangeColorTemperature()'
            - 'iaa.Clouds()'
      batch_size: 128
      pin_memory: True
      num_workers: 12
      drop_last: False
      shuffle: True

  train_eval:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: dataset.rotation.rotation_dataset
        class: DocOrientationDataset
        DocOrientationDataset:
          data_dirs:
            - '''/extdata/ocr/phungpx/projects/PHUNGPX/semantic_segmentation_pytorch/dataset/NATCOM2/train'''
          classes:
            CARD_FRONT_TYPE_1: 0
            CARD_BACK_TYPE_1: 1
          image_patterns:
            - '''**/*_quad.jpg'''
            - '''**/*_quad.png'''
            - '''**/*_quad.jpeg'''
            - '''**/*_quad.JPG'''
            - '''**/*_quad.PNG'''
            - '''**/*_quad.JPEG'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          image_size: (224, 224)
          inner_size: 256
      batch_size: 128
      pin_memory: True
      num_workers: 12
      drop_last: False
      shuffle: False

  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: dataset.rotation.rotation_dataset
        class: DocOrientationDataset
        DocOrientationDataset:
          data_dirs:
            - '''/extdata/ocr/phungpx/projects/PHUNGPX/semantic_segmentation_pytorch/dataset/NATCOM2/valid'''
          classes:
            CARD_FRONT_TYPE_1: 0
            CARD_BACK_TYPE_1: 1
          image_patterns:
            - '''**/*_quad.jpg'''
            - '''**/*_quad.png'''
            - '''**/*_quad.jpeg'''
            - '''**/*_quad.JPG'''
            - '''**/*_quad.PNG'''
            - '''**/*_quad.JPEG'''
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
          image_size: (224, 224)
          inner_size: 256
      batch_size: 128
      pin_memory: True
      num_workers: 12
      drop_last: False
      shuffle: False

loss:
  module: loss.classification.loss
  class: Loss
  Loss:
    loss_fn:
      module: torch.nn
      class: CrossEntropyLoss
    output_transform: 'lambda x: (x[0], x[1])'

model:
  module: model.classification.mobilenets
  class: MobileNetV3Small
  MobileNetV3Small:
    num_classes: 4
    pretrained: True

optim:
  module: torch.optim
  class: Adam
  Adam:
    params: config['model'].parameters()
    lr: 0.001
    amsgrad: True

early_stopping:
  module: handler.early_stopping
  class: EarlyStopping
  EarlyStopping:
    evaluator_name: '''valid'''
    patience: 50
    delta: 0
    mode: '''min'''
    score_name: '''loss'''
    
metric:
  module: metric.metric_base
  class: Metrics
  Metrics:
    metrics:
      accuracy:
        module: metric.classification.metric_fns
        class: Metric
        Metric:
          metric_fn:
            module: metric.classification.metric_fns
            class: Accuracy
            Accuracy:
              num_classes: 4
          output_transform: 'lambda x: (x[0].softmax(dim=1), x[1])'
      loss:
        module: metric.loss
        class: Loss
        Loss:
          loss_fn:
            module: torch.nn
            class: CrossEntropyLoss
          output_transform: 'lambda x: (x[0], x[1])'

writer:
  module: handler.writer
  class: Writer
  Writer:
    save_dir: '''checkpoint/rotation/NATCOM'''

logger:
  module: handler.logger
  class: Logger
  Logger:
    save_dir: '''checkpoint/rotation/NATCOM'''
    mode: logging.DEBUG
    format: '''%(asctime)s - %(name)s - %(levelname)s - %(message)s'''

plot:
  module: handler.plot
  class: Plot
  Plot:
    save_dir: '''checkpoint/rotation/NATCOM'''

lr_scheduler:
  module: torch.optim.lr_scheduler
  class: ReduceLROnPlateau
  ReduceLROnPlateau:
    optimizer: config['optim']
    mode: '''min'''
    factor: 0.1
    patience: 10
    verbose: True

model_info:
  module: trainer.utils
  class: ModelInfo
  ModelInfo:
    verbose: True
    input_shape: '(224, 224, 3)'

trainer:
  module: trainer.trainer
  class: Trainer
  Trainer:
    model: config['model']
    data: config['data']
    loss: config['loss']
    optim: config['optim']
    metric: config['metric']
    early_stopping: config['early_stopping']
    lr_scheduler: config['lr_scheduler']
    logger: config['logger']
    writer: config['writer']
    plot: config['plot']
    model_info: config['model_info']
    save_dir: '''checkpoint/rotation/NATCOM'''
    config_save: config

extralibs:
  torch: torch
  iaa: imgaug.augmenters
  logging: logging
  torchvision: torchvision
  transforms: torchvision.transforms
